{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from numpy import array\n",
    "import string\n",
    "import pickle as plk\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Embedding\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LEN = 60\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 10\n",
    "HIDDEN_LAYERS_DIM = 512\n",
    "LAYER_COUNT = 4\n",
    "DROPOUT = 0.2\n",
    "\n",
    "df = pd.read_excel('/Users/luyin/Desktop/project/Q&A.xlsx',header = 0)\n",
    "l = df['Breakout'].unique() # 79 unique analyst\n",
    "dic = {} #create dictionary for questions\n",
    "for category in l:\n",
    "    list_ = list(df.loc[df['Breakout']  == category]['Question'])\n",
    "    dic[category] = list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary len = 98\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', ' ', '\\t', '\\n', '\\r', '<unk>']\n"
     ]
    }
   ],
   "source": [
    "#character vocabulary\n",
    "UNK_IDX = 98\n",
    "characters = list(string.printable)\n",
    "characters.remove('\\x0b')\n",
    "characters.remove('\\x0c')\n",
    "VOCABULARY_SIZE = len(characters)\n",
    "characters_to_ix = {c:i for i,c in enumerate(characters)}\n",
    "print(\"vocabulary len = %d\" % VOCABULARY_SIZE)\n",
    "characters.append('<unk>')\n",
    "print(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_len = len(dic['Balance sheet'])\n",
    "all_data = dic['Balance sheet']\n",
    "train_data = dic['Balance sheet'][:600]\n",
    "val_data = dic['Balance sheet'][600: dic_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def letter_generator(data):\n",
    "    out_text = ''\n",
    "    for i in range(len(data)):\n",
    "        out = ''\n",
    "        for letter in data[i]:\n",
    "            out += letter\n",
    "        out_text += out\n",
    "    return out_text\n",
    "\n",
    "def describe_batch(X, y, samples=3):\n",
    "\n",
    "    for i in range(samples):\n",
    "        sentence = \"\"\n",
    "        for s in range(SEQUENCE_LEN):\n",
    "            sentence += characters[X[i,s,:].argmax()]\n",
    "        next_char = characters[y[i,:].argmax()]\n",
    "        \n",
    "        print(\"sample #%d: ...%s -> '%s'\" % (\n",
    "            i,\n",
    "            sentence[-20:],\n",
    "            next_char\n",
    "        ))\n",
    "\n",
    "def batch_generator(text, count):\n",
    "\n",
    "    while True:\n",
    "        for batch_ix in range(count):\n",
    "            X = np.zeros((BATCH_SIZE, SEQUENCE_LEN, VOCABULARY_SIZE+1))\n",
    "            y = np.zeros((BATCH_SIZE, VOCABULARY_SIZE+1))\n",
    "\n",
    "            batch_offset = BATCH_SIZE * batch_ix\n",
    "\n",
    "            for sample_ix in range(BATCH_SIZE):\n",
    "                sample_start = batch_offset + sample_ix\n",
    "                for s in range(SEQUENCE_LEN):\n",
    "                    if text[sample_start+s] in characters_to_ix.keys():\n",
    "                        X[sample_ix, s, characters_to_ix[text[sample_start+s]]] = 1\n",
    "                    else:\n",
    "                        X[sample_ix, s, UNK_IDX] = 1\n",
    "                if text[sample_start+s+1] in characters_to_ix.keys():\n",
    "                    y[sample_ix, characters_to_ix[text[sample_start+s+1]]]=1\n",
    "                else:\n",
    "                    y[sample_ix, UNK_IDX]=1\n",
    "            yield X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = letter_generator(train_data)\n",
    "val_text = letter_generator(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train_text.txt', 'w')\n",
    "file.write(train_text)\n",
    "file.close()\n",
    "\n",
    "file = open('val_text.txt', 'w')\n",
    "file.write(val_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total of 284224 characters\n",
      "sample #0: ...utlook for how the n -> 'e'\n",
      "sample #1: ...tlook for how the ne -> 't'\n",
      "sample #2: ...look for how the net -> ' '\n",
      "sample #3: ...ook for how the net  -> 'i'\n",
      "sample #4: ...ok for how the net i -> 'n'\n"
     ]
    }
   ],
   "source": [
    "with open('train_text.txt', \"r\") as f:\n",
    "    text_train = f.read()\n",
    "with open('val_text.txt', \"r\") as f:\n",
    "    text_val = f.read()\n",
    "\n",
    "text_train_len = len(text_train)\n",
    "text_val_len = len(text_val)\n",
    "print(\"Total of %d characters\" % (text_train_len + text_val_len))\n",
    "\n",
    "for ix, (X,y) in enumerate(batch_generator(text_train, count=1)):\n",
    "    # describe some samples from the first batch\n",
    "    describe_batch(X, y, samples=5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    \"\"\"Build a Keras sequential model for training the char-rnn\"\"\"\n",
    "    model = Sequential()\n",
    "    for i in range(LAYER_COUNT):\n",
    "        model.add(\n",
    "            Bidirectional(LSTM(\n",
    "                HIDDEN_LAYERS_DIM, \n",
    "                return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
    "                input_shape=(SEQUENCE_LEN, VOCABULARY_SIZE+1),\n",
    "            )) # add a Bidiretional \n",
    "        )\n",
    "        model.add(Dropout(DROPOUT))\n",
    "    \n",
    "    model.add(Dense(VOCABULARY_SIZE+1))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training batch count: 442\n",
      "validation batch count: 112\n"
     ]
    }
   ],
   "source": [
    "training_model = build_model()\n",
    "\n",
    "train_batch_count = (text_train_len - SEQUENCE_LEN) // BATCH_SIZE\n",
    "val_batch_count = (text_val_len - SEQUENCE_LEN) // BATCH_SIZE\n",
    "print(\"training batch count: %d\" % train_batch_count)\n",
    "print(\"validation batch count: %d\" % val_batch_count)\n",
    "\n",
    "# checkpoint\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "# filepath = \"./%d_%d-%s_dp%.2f_%dS_epoch{epoch:02d}-loss{loss:.4f}-val-loss{val_loss:.4f}_weights\" % (\n",
    "#     BATCH_SIZE,\n",
    "#     LAYER_COUNT,\n",
    "#     HIDDEN_LAYERS_DIM,\n",
    "#     DROPOUT,\n",
    "#     SEQUENCE_LEN)\n",
    "filepath=\"char_RNN_2.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, save_weights_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#Â early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=0)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = training_model.fit_generator(\n",
    "#     batch_generator(text_train, count=train_batch_count),\n",
    "#     train_batch_count,\n",
    "#     max_queue_size=1, # no more than one queued batch in RAM\n",
    "#     epochs=EPOCHS,\n",
    "#     callbacks=callbacks_list,\n",
    "#     validation_data=batch_generator(text_val, count=val_batch_count),\n",
    "#     validation_steps=val_batch_count,\n",
    "#     initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "442/442 [==============================] - 5838s 13s/step - loss: 1.1813 - acc: 0.6529 - val_loss: 1.1830 - val_acc: 0.6598\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.18133, saving model to char_RNN_2.hdf5\n",
      "Epoch 2/10\n",
      " 37/442 [=>............................] - ETA: 1:19:45 - loss: 1.1335 - acc: 0.6613"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f733940aaf61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_batch_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     initial_epoch=0)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlps/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_model_2 = build_model()\n",
    "filepath=\"char_RNN_2.hdf5\"\n",
    "# checkpoint = ModelCheckpoint(filepath, save_weights_only=True)\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "#Â early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=0)\n",
    "\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "training_model_2.load_weights(filepath)\n",
    "history_2 = training_model_2.fit_generator(\n",
    "    batch_generator(text_train, count=train_batch_count),\n",
    "    train_batch_count,\n",
    "    max_queue_size=1, # no more than one queued batch in RAM\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks_list,\n",
    "    validation_data=batch_generator(text_val, count=val_batch_count),\n",
    "    validation_steps=val_batch_count,\n",
    "    initial_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model_2.save('char_rnn_model_new3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = Sequential()\n",
    "for i in range(LAYER_COUNT):\n",
    "    test_model.add(\n",
    "            LSTM(\n",
    "                HIDDEN_LAYERS_DIM, \n",
    "                return_sequences=True if (i!=(LAYER_COUNT-1)) else False,\n",
    "                batch_input_shape=(1, 1, VOCABULARY_SIZE+1),\n",
    "                stateful=True\n",
    "            )\n",
    "        )\n",
    "test_model.add(Dense(VOCABULARY_SIZE+1))\n",
    "test_model.add(Activation('softmax'))\n",
    "test_model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model.load_weights(\"char_RNN_2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def predict_next_char(model, current_char, diversity=1.0):\n",
    "\n",
    "    x = np.zeros((1, 1, VOCABULARY_SIZE+1))\n",
    "    if current_char in characters_to_ix.keys():\n",
    "        x[:,:,characters_to_ix[current_char]] = 1\n",
    "        y = model.predict(x, batch_size=1)\n",
    "        next_char_ix = sample(y[0,:], temperature=diversity)\n",
    "        next_char = characters[next_char_ix]\n",
    "    return next_char\n",
    "\n",
    "\n",
    "\n",
    "def generate_text(model, seed, count=300):\n",
    "\n",
    "    model.reset_states()\n",
    "    for s in seed[:-1]:\n",
    "        next_char = predict_next_char(model, s)\n",
    "    current_char = seed[-1]\n",
    "\n",
    "    sys.stdout.write(\"[\"+seed+\"]\")\n",
    "    \n",
    "    for i in range(count - len(seed)):\n",
    "        next_char = predict_next_char(model, current_char, diversity=0.5)\n",
    "        current_char = next_char\n",
    "        sys.stdout.write(next_char)\n",
    "    print(\"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[think about] the securities being the deposit betas when we saw a little bit about the bank to account that you are some of the consumer balance sheet relative to the asset side, you're aghitional expecting the point in terms of the loan growth about the consumer this quarter and the security in the ...\n",
      "\n",
      "[think about] the consumer and do you think the outlook loan growth in the bank to your consumer and the loan base has of the consumer deposit betas that so far, and it was you have to a back to increase in the deposit rate hikes? Or a little bit about the deposits of the callable for balance sheet th...\n",
      "\n",
      "[think about] the retail sense of the consumer banks, are you asset side of the bong that you have it a a little bit on the concern of the bank higher things out the balance sheet related to the short rate environment, and I have in terms of the outlook of the auto a that with the past consumer of the...\n",
      "\n",
      "[think about] the bank and interest income is the people related to mater the balance sheet deposit betas and then the consumer banks and the banks and more and as well as the consumer than your competitors that concern as wells of the deposit betas and a little bit about the outlook loan growth conce...\n",
      "\n",
      "[think about] the consumers and which is there a bit on the deposit base in terms of the bank the past because the loan growth in the consumer but are you have a sense of the other book securities particular concertion out the consumer balance sheet, and I think your deposit betas and when you are abo...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    generate_text(\n",
    "        test_model,\n",
    "        seed=\"think about\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[What] do you think that are the industry is about deposit betas are you particular and the banks to get that you want to have to make in the customers and that concernion the balance sheet roll of the loan growth concers to what have a lot of the consumer being sense of the deposit side of the balanc...\n",
      "\n",
      "[What] the deposit betas where you are in the bank deposit changes and have your bank into the outlook for that says a little bit of the balance sheet in terms of your did loan growth your deposit growth in loan growth in the consumer particular to the part of the customers and where you think is a li...\n",
      "\n",
      "[What] we should we think is a bit continue to retail growth of that from a sense of your corporate and the positioned from the concertion in the loan growth in the part of the consumer banks and so the outlook for the retail side?Good morning. And if you all a little bit about your competitors from h...\n",
      "\n",
      "[What] your takes and the deposit betas that we saw a little bit about the particular consumer what you're seeing the corporate side and the CCE last quarter for a conporate that you are in the banks have a deposit beta is the deposits to reall to be a little bit mentioned the balance sheet that you h...\n",
      "\n",
      "[What] we pretty in the deposit consumers to expect to what the consumer and the balance sheet new higher there also the industry can and retail premium for the loan growth in terms of how you think about the Fed balance sheet related to grow that how has a lot of the industry, so you all the better a...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    generate_text(\n",
    "        test_model,\n",
    "        seed=\"What\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
